# Text_to_Image_Generation_Moderation
Moderator is a safety system for text-to-image diffusion models that uses context-aware policies to detect and manage harmful or sensitive prompts. It offers users options to replace, remove, or Mosaic blur such content before image generation, ensuring ethical and secure AI image creation.
